# Attention-based End-to-end Speech-to-text Translation Neural Network
This project translates speech recordings to their corresponding transcripts. The recordings were converted to spectrograms ahead of time, which contains 40 frequencies, and were then fed into a character-based model. The model consists of an encoder and an attention-based decoder. The encoder uses a pyramidal-LSTM to extract speech embeddings, and the decoder will focus on important parts of embeddings and generate the corresponding translation. 
