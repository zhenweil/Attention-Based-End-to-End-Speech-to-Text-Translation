# Attention-based End-to-end Speech-to-text Translation Neural Network
This project translates speech recordings to their corresponding transcripts. Recordings were converted to spectrograms ahead of time, which contains 40 frequencies, and were then fed into a character-based model. The model consists of an encoder and an attention-based decoder. The encoder uses a pyramidal-LSTM to extract speech embeddings, and the decoder will focus on important parts of embeddings and is able to generate the corresponding translation. 
