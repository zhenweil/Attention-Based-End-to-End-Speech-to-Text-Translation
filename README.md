# Attention-based End-to-end Speech-to-text Translation Neural Network
This project translates speech recordings to their corresponding transcripts. Recordings were converted to spectrograms ahead of time, which contains 40 frequencies, and were then fed into a character-based model. The model consists of an encoder and an attention-based decoder. The encoder uses a pyramidal-LSTM to extract speech embeddings, and the decoder learns to focus on important portion of embeddings and is able to generate corresponding translations. 
